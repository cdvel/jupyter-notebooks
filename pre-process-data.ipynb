{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process data\n",
    "\n",
    "Expose the structure of the problem through the following techniques:\n",
    "\n",
    "- Rescale\n",
    "- Standarize\n",
    "- Normalize\n",
    "- Binarize\n",
    "\n",
    "Different algorithms may require different transformations (different assumptions). Some transforms may not benefit certain algorithms. A good approach is to create multiple views and transform of the data, then apply some algorithms to each view to discard and indentify transforms that expose the problem structure better.\n",
    "\n",
    "##### Steps\n",
    "\n",
    "1. Load the dataset url\n",
    "2. Split the dataset into *input* and *output* variables for ML\n",
    "3. Apply a preprocessing transform to the *input*\n",
    "4. Summarize the data to show the change\n",
    "\n",
    "** Scikit-learn\n",
    "\n",
    "Provides 2 standard transformation methods that can be applied to existing and future training data\n",
    "http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing\n",
    "\n",
    "Transforms:\n",
    "\n",
    "- Fit and Multiple Transform [preferred]\n",
    "\n",
    "1. fit()\n",
    "Prepares the parameters of the transform once on your data\n",
    "\n",
    "2. transform()\n",
    "Use in the same data to prepare for modelling and again on the test and validation dataset, and again on new data.\n",
    "\n",
    "- Combined Fit-And-Transform\n",
    "\n",
    "Use for one off tasks, good for plotting or summarizing data,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Rescale Data\n",
    "\n",
    "Use when data is compromised of attributes of varying scales, and algorithm benefits from all attributes in same scale. Also known as Normalization, with values between 1 and 0. \n",
    "\n",
    "Useful in:\n",
    "- optimization algorithms (core ML) like gradient descent.\n",
    "- Algorithms that weight inputs like regression and NN\n",
    "- Algorithms that use distance measures like k-Nearest neighbours\n",
    "\n",
    "Using scikit-learn's `MinMaxScaler` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "# separate IN and OUT components\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.000e+00   1.480e+02   7.200e+01   3.500e+01   0.000e+00   3.360e+01\n",
      "    6.270e-01   5.000e+01]\n",
      " [  1.000e+00   8.500e+01   6.600e+01   2.900e+01   0.000e+00   2.660e+01\n",
      "    3.510e-01   3.100e+01]\n",
      " [  8.000e+00   1.830e+02   6.400e+01   0.000e+00   0.000e+00   2.330e+01\n",
      "    6.720e-01   3.200e+01]\n",
      " [  1.000e+00   8.900e+01   6.600e+01   2.300e+01   9.400e+01   2.810e+01\n",
      "    1.670e-01   2.100e+01]\n",
      " [  0.000e+00   1.370e+02   4.000e+01   3.500e+01   1.680e+02   4.310e+01\n",
      "    2.288e+00   3.300e+01]]\n",
      "[[ 0.353  0.744  0.59   0.354  0.     0.501  0.234  0.483]\n",
      " [ 0.059  0.427  0.541  0.293  0.     0.396  0.117  0.167]\n",
      " [ 0.471  0.92   0.525  0.     0.     0.347  0.254  0.183]\n",
      " [ 0.059  0.447  0.541  0.232  0.111  0.419  0.038  0.   ]\n",
      " [ 0.     0.688  0.328  0.354  0.199  0.642  0.944  0.2  ]]\n"
     ]
    }
   ],
   "source": [
    "#...\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "# sumarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print X[0:5,:]\n",
    "print rescaledX[0:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Standarize Data\n",
    "\n",
    "Useful for attributes with a Gaussian distribution and differing mean and standard deviation. It transform to a set of atrributes with mean of 0 and standard deviation of 1.\n",
    "\n",
    "Suitable for techniques assuming a Gaussian distribution in the input, and work better with rescaled data, e.g., \n",
    "\n",
    "- linear regression\n",
    "- logistic regression\n",
    "- linear discriminate analysis\n",
    "\n",
    "\n",
    "Using scikit-learn's `StandardScaler` class:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.000e+00   1.480e+02   7.200e+01   3.500e+01   0.000e+00   3.360e+01\n",
      "    6.270e-01   5.000e+01]\n",
      " [  1.000e+00   8.500e+01   6.600e+01   2.900e+01   0.000e+00   2.660e+01\n",
      "    3.510e-01   3.100e+01]\n",
      " [  8.000e+00   1.830e+02   6.400e+01   0.000e+00   0.000e+00   2.330e+01\n",
      "    6.720e-01   3.200e+01]\n",
      " [  1.000e+00   8.900e+01   6.600e+01   2.300e+01   9.400e+01   2.810e+01\n",
      "    1.670e-01   2.100e+01]\n",
      " [  0.000e+00   1.370e+02   4.000e+01   3.500e+01   1.680e+02   4.310e+01\n",
      "    2.288e+00   3.300e+01]]\n",
      "[[ 0.64   0.848  0.15   0.907 -0.693  0.204  0.468  1.426]\n",
      " [-0.845 -1.123 -0.161  0.531 -0.693 -0.684 -0.365 -0.191]\n",
      " [ 1.234  1.944 -0.264 -1.288 -0.693 -1.103  0.604 -0.106]\n",
      " [-0.845 -0.998 -0.161  0.155  0.123 -0.494 -0.921 -1.042]\n",
      " [-1.142  0.504 -1.505  0.907  0.766  1.41   5.485 -0.02 ]]\n"
     ]
    }
   ],
   "source": [
    "#...\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "# summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print X[0:5,:]\n",
    "print rescaledX[0:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 3. Normalize Data\n",
    "\n",
    "Normalize = Scale each observation to have a length of 1. Useful for sparse datasets (many zeros) with attributes of varying scales, best for:\n",
    "\n",
    "- NNs, Algorithms that weight input values\n",
    "- k-Nearest Neighbors, Algorithms that use distance measures\n",
    "\n",
    "Using scikit-learn's `Normalizer` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.034  0.828  0.403  0.196  0.     0.188  0.004  0.28 ]\n",
      " [ 0.008  0.716  0.556  0.244  0.     0.224  0.003  0.261]\n",
      " [ 0.04   0.924  0.323  0.     0.     0.118  0.003  0.162]\n",
      " [ 0.007  0.588  0.436  0.152  0.622  0.186  0.001  0.139]\n",
      " [ 0.     0.596  0.174  0.152  0.731  0.188  0.01   0.144]]\n"
     ]
    }
   ],
   "source": [
    "# ...\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "normalizedX =  scaler.transform(X)\n",
    "\n",
    "#summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print normalizedX[0:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Binarize Data\n",
    "\n",
    "Transform data using a binary threshold. Values above threshold marked as *1*, equal and below marked as *0*\n",
    "\n",
    "Useful when you have probabilities that you want crisp values, or for feature engineering (add something meaningful)\n",
    "\n",
    "Using scikit-learn's `Binarizer` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.  1.  0.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  0.  1.  1.  1.]\n",
      " [ 1.  1.  1.  0.  0.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.  1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "#...\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "binarizer = Binarizer(threshold=0.0).fit(X)\n",
    "binaryX = binarizer.transform(X)\n",
    "\n",
    "# summarize transformed data\n",
    "\n",
    "set_printoptions(precision=3)\n",
    "print binaryX[0:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Source: Jason Brownleee"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
