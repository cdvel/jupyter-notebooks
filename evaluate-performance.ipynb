{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating performance of ML algorithms\n",
    "\n",
    "2 ways:\n",
    "    \n",
    "1. Make predictions for unseen data that you already know the answer\n",
    "2. Use statistics (resampling methods), to estimate performance on new data\n",
    "\n",
    "\n",
    "#### Evaluate Algorithms\n",
    "\n",
    "Overfitting, will occur if same data used during preparation is used to evaluate performance (perfect score in the same training set, new data performance very poor)\n",
    "\n",
    "Evaluation estimates how well the algo will do in practice, no guarantees. After estimation, retrain algo in the whole dataset and make it ready:\n",
    "\n",
    "Techniques to split dataset, and create useful estimates:\n",
    "\n",
    "- Train and Test Sets\n",
    "- k-fold Cross-Validation\n",
    "- Leave One Out Cross-Validation\n",
    "- Repeated Random Test-Train Splits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into Train and Test Sets\n",
    "\n",
    "Break your data into training and testing datasets. \n",
    "\n",
    "From the original dataset: Train algo in part 1, use part 2 to make predictions against the expected results. A common split is 67% training, 33% testing but depends on size and specifics of each dataset\n",
    "\n",
    "Fast, and ideal for large datasets where both splits represent the problem accurately. Can have strong variance (may result in noticeable differences between training and test sets).\n",
    "\n",
    "For example, evaluating the accuracy of a Logistic Regression model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 75.591%\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "#size of the split\n",
    "test_size = 0.33\n",
    "# help results to be reproducible, same randoms each run; needed when comparing\n",
    "seed = 7\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print (\"Accuracy %.3f%%\") % (result*100.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-fold Cross-Validation\n",
    "\n",
    "Approach with less variance than Split (above), breaks the dataset in k-parts or folds. Algo is trained in k-1 folds, one held back. Repeated until each fold is held back once. End up with k different performance scores, summarized using a mean and a standard deviation.\n",
    "    \n",
    "The result is more accurate prediction in new data. k is chosen so each fold has a reasonable size (sample problem) -- While allowing enough repetitions to train and estimate unseen data.\n",
    "\n",
    "modest datasets of 1000s - 10000s of records, k = 3, 5, 10 are common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 76.951% (4.841%)\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print (\"Accuracy %.3f%% (%.3f%%)\") % (results.mean()*100.0, results.std()*100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave One Out Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeated Random Test-Train Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
